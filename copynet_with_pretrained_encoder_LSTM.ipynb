{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "copynet_withvae_lstm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwhyoMpnZEz1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "663ad6e2-0d0a-46bc-d68f-1b2f036ecb95"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import tensorflow as tf\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as  plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from tensorflow import keras\n",
        "\n",
        "import tensorflow as tf\n",
        "#fitting for gpu\n",
        "\n",
        "\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.compat.v1.Session(config=config)\n",
        "\n",
        "df_clean = pd.read_csv(\"./drive/My Drive/total_data.csv\")\n",
        "#---------------------------------------------------------------------------------------\n",
        "given_ingredient = list(df_clean.ingredients)[0:192]\n",
        "#-----------------------------创建评估用词表--------------------------------------------\n",
        "reference_recipe = list(df_clean.recipes)\n",
        "reference_meteor = []\n",
        "references = []\n",
        "reference_list = reference_recipe[0:192]\n",
        "for astr in reference_list:\n",
        "    alist = astr.split(' ')[1:-1]\n",
        "    reference_meteor.append(' '.join(alist))\n",
        "    references.append([alist])\n",
        "clean_summaries = list(df_clean.ingredients)\n",
        "clean_texts = list(df_clean.recipes)\n",
        "sp_dataset = tuple(clean_summaries)\n",
        "en_dataset = tuple(clean_texts)\n",
        "#将词语式数据转成ID式\n",
        "def tokenizer(lang):\n",
        "    lang_tokenizer = keras.preprocessing.text.Tokenizer(\n",
        "        num_words=None, filters='', split=' ')\n",
        "    lang_tokenizer.fit_on_texts(lang)#统计词频，生成词表\n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "    tensor = keras.preprocessing.sequence.pad_sequences(tensor, padding='post')#在句子后面做padding\n",
        "    return tensor, lang_tokenizer\n",
        "\n",
        "input_tensor, input_tokenizer = tokenizer(sp_dataset)\n",
        "output_tensor, output_tokenizer = tokenizer(en_dataset)\n",
        "\n",
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "\n",
        "max_length_input = max_length(input_tensor)\n",
        "max_length_output = max_length(output_tensor)\n",
        "print(max_length_input, max_length_output)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "input_train, input_eval, output_train, output_eval = train_test_split(input_tensor[192:], output_tensor[192:], test_size=0.01, shuffle=False)\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_train, output_train))\n",
        "train_dataset = dataset.repeat(epochs).batch(batch_size, drop_remainder= True)\n",
        "train_dataset = train_dataset.shuffle(10000)\n",
        "eval_dataset = tf.data.Dataset.from_tensor_slices((input_eval, output_eval))\n",
        "eval_dataset = eval_dataset.repeat(epochs).batch(batch_size, drop_remainder= True)\n",
        "\n",
        "for x, y in train_dataset.take(1):\n",
        "    print(x.shape)\n",
        "    print(y.shape)\n",
        "    print(x)\n",
        "    print(y)\n",
        "\n",
        "embedding_units = 256\n",
        "units = 256\n",
        "#input_tokenizer.word_index是个字典\n",
        "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
        "output_vocab_size = len(output_tokenizer.word_index) + 1\n",
        "print(input_vocab_size,output_vocab_size)\n",
        "\n",
        "#-------------------lstm-----------------------------------\n",
        "class Encoder(keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_units, encoding_units, batch_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.encoding_units = encoding_units\n",
        "        self.embedding = keras.layers.Embedding(vocab_size, embedding_units)\n",
        "        #由于用attention，每步输出需要return_sequences = True\n",
        "        self.gru = keras.layers.LSTM(self.encoding_units,\n",
        "                                   return_sequences = True,\n",
        "                                   return_state = True,\n",
        "                                   recurrent_initializer = 'glorot_uniform')\n",
        "        \n",
        "        \n",
        "    #hidden是初始化的隐含状态\n",
        "    #这里hidden应该变成[hiddenstate,hiddenc]\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state, state_c = self.gru(x, initial_state = hidden)\n",
        "        #output = keras.layers.Dropout(0.75)(output)\n",
        "        return output, state, state_c\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return [tf.zeros((self.batch_size, self.encoding_units)),tf.zeros((self.batch_size, self.encoding_units))]\n",
        "    \n",
        "encoder = Encoder(input_vocab_size, embedding_units, units, batch_size)\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden, sample_c = encoder.call(x, sample_hidden)\n",
        "\n",
        "print('sample_output.shape: ', sample_output.shape)\n",
        "print('sample_hidden.shape: ', sample_hidden.shape)\n",
        "print('sample_memory.shape: ', sample_c.shape)\n",
        "\n",
        "class BahdanauAttention(keras.Model):\n",
        "    \n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = keras.layers.Dense(units)\n",
        "        self.W2 = keras.layers.Dense(units)\n",
        "        self.V = keras.layers.Dense(1)\n",
        "        \n",
        "    def call(self, decoder_hidden, encoder_outputs):\n",
        "        #decoder_hidden.shape = (batch_size, units)\n",
        "        #encoder_outputs.shape = (batch_size, length, units)\n",
        "        decoder_hidden_with_time_axis = tf.expand_dims(decoder_hidden, 1)#decoder_hidden.shape = (batch_size, 1, units)\n",
        "        #before V:tf.nn.tanh/shape: (batch_size, length, units)\n",
        "        #after V:(batch_size, length, 1)\n",
        "        score = self.V(\n",
        "            tf.nn.tanh(\n",
        "                self.W1(encoder_outputs) + self.W2(decoder_hidden_with_time_axis)))\n",
        "        \n",
        "        #shape: (batch_size, length, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis = 1)\n",
        "        #context_vector.shape:(batch_size, length, units)\n",
        "        context_vector = attention_weights * encoder_outputs\n",
        "        #context_vector.shape:(batch_size, units)\n",
        "        context_vector = tf.reduce_sum(context_vector, axis = 1)#在length上求和\n",
        "        \n",
        "        return context_vector, attention_weights\n",
        "\n",
        "attention_model = BahdanauAttention(units = 10)#units:经过W1之后的units个数，与batch_size, length, units里units不同\n",
        "attention_results, attention_weights = attention_model.call(sample_hidden,sample_output)\n",
        "\n",
        "print(attention_results.shape)\n",
        "print(attention_weights.shape)\n",
        "\n",
        "#---------------------------------lstm-----------------------------------------\n",
        "class Decoder(keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_units, decoding_units, batch_size):\n",
        "        super(Decoder, self).__init__()#调用父类（keras.Model）的构造函数\n",
        "        self.batch_size = batch_size\n",
        "        self.decoding_units = decoding_units\n",
        "        self.embedding = keras.layers.Embedding(vocab_size, embedding_units)\n",
        "        self.gru = keras.layers.LSTM(self.decoding_units,\n",
        "                                   return_sequences = True,\n",
        "                                   return_state = True,\n",
        "                                   recurrent_initializer = 'glorot_uniform')\n",
        "        \n",
        "        self.fc = keras.layers.Dense(vocab_size)\n",
        "        self.attention = BahdanauAttention(self.decoding_units)\n",
        "        \n",
        "        #x:当前步输入，hidden:前一步输出\n",
        "    def call(self, x, hidden, encoding_outputs,encoding_state):\n",
        "        #context_vector.shape: (bathc_size, units)\n",
        "        context_vector, attention_weights = self.attention.call(hidden, encoding_outputs)\n",
        "        #befor embedding:x.shape:(batch_size, 1)\n",
        "        #after embedding:x.shape:(batch_size, 1, embedding_units)\n",
        "        \n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        combined_x = tf.concat([tf.expand_dims(context_vector, 1),x], axis = -1)\n",
        "        #output.shape: (batch_size, 1, decoding_units)\n",
        "        #state.shape: (batch_size, decoding_units)\n",
        "        output, state, state_c = self.gru(combined_x, initial_state = [hidden,encoding_state])\n",
        "        #output = keras.layers.Dropout(0.5)(output)\n",
        "        #output.shape: (batch_size, decoding_units)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        \n",
        "        #output.shape: (batch_size, vocab_size)\n",
        "        output = self.fc(output)\n",
        "        \n",
        "        return context_vector, output, state, attention_weights, state_c\n",
        "decoder = Decoder(output_vocab_size, embedding_units, units, batch_size)\n",
        "\n",
        "outputs = decoder.call(tf.random.uniform((batch_size,1)), sample_hidden, sample_output,sample_hidden)\n",
        "\n",
        "context_vector, decoder_output, decoder_hidden, decoder_aw, state_c = outputs\n",
        "\n",
        "print(decoder_output.shape)\n",
        "print(decoder_hidden.shape)\n",
        "print(decoder_aw.shape)\n",
        "\n",
        "optimizer = keras.optimizers.Adam()\n",
        "\n",
        "loss_object = keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = 'none')\n",
        "#from_logits直接经过fc的输出没有经过softmax,如果经过softmax就设成False\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    #输出里的padding不应该计算到损失函数中去\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))#是padding时，mask取0\n",
        "    loss_ = loss_object(real, pred)\n",
        "    mask = tf.cast(mask, dtype = loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    \n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "W11 = keras.layers.Dense(1)\n",
        "W22 = keras.layers.Dense(1)\n",
        "W33 = keras.layers.Dense(1)\n",
        "\n",
        "\n",
        "#lstm-----------------------------------------\n",
        "#@tf.function#加速cell\n",
        "def train_step(inp, targ, encoding_hidden):\n",
        "    loss = 0\n",
        "    with tf.GradientTape() as tape:\n",
        "        encoding_outputs, encoding_hidden, encoding_c = encoder(inp, encoding_hidden)\n",
        "        inp = inp.numpy()\n",
        "        decoding_hidden = encoding_hidden\n",
        "        decoding_state = encoding_c\n",
        "        #eg: <start> I am here <end>\n",
        "        #1. <start> -> I\n",
        "        #2. I -> am\n",
        "        #3. am -> here\n",
        "        #4. here -> <end>\n",
        "        for t in range(0, targ.shape[1]-1):\n",
        "            decoding_input = tf.expand_dims(targ[:, t],1)\n",
        "            context_vector, predictions, decoding_hidden, decoding_aw, decoding_state = decoder.call(decoding_input, decoding_hidden, encoding_outputs,decoding_state)\n",
        "            #由decoding.call返回的三维decoding_aw\n",
        "            attention_weights = np.reshape(decoding_aw, (-1, 35))\n",
        "            adpre = np.zeros((64,6728))\n",
        "            \n",
        "            for index1,sen in enumerate(inp):\n",
        "                for index2, word_index in enumerate(sen):\n",
        "                #int means only integer can be used as indices\n",
        "                    adpre[index1][int(word_index)] = attention_weights[index1][index2]\n",
        "            #tf.nn.sigmoid之前shape应该是64,1\n",
        "            prob = tf.nn.sigmoid(W11(context_vector) + W22(decoding_hidden) + W33(decoding_input))\n",
        "            #print(prob.shape)\n",
        "            adpre = tf.convert_to_tensor(adpre,tf.float32)\n",
        "            #prob = tf.conver_to_tensor(prob)\n",
        "            #print(prob)\n",
        "            #print(adpre)\n",
        "            new_prediction = (1-prob) * adpre + prob * predictions\n",
        "            loss += loss_function(targ[:, t+1],new_prediction)\n",
        "            \n",
        "    batch_loss = loss / int(targ.shape[0])\n",
        "        \n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables + W11.trainable_variables + W22.trainable_variables + W33.trainable_variables\n",
        "        \n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "        \n",
        "    return batch_loss   \n",
        "\n",
        "#-------------------------------------------lstm-------------------------\n",
        "def eval_step(inp, targ, encoding_hidden):\n",
        "    loss = 0\n",
        "    \n",
        "    encoding_outputs, encoding_hidden, encoding_c = encoder(inp, encoding_hidden)\n",
        "    inp = inp.numpy()\n",
        "    decoding_hidden = encoding_hidden\n",
        "    decoding_state = encoding_c\n",
        "        #eg: <start> I am here <end>\n",
        "        #1. <start> -> I\n",
        "        #2. I -> am\n",
        "        #3. am -> here\n",
        "        #4. here -> <end>\n",
        "    for t in range(0, targ.shape[1]-1):\n",
        "        decoding_input = tf.expand_dims(targ[:, t],1)\n",
        "        context_vector, predictions, decoding_hidden, decoding_aw, decoding_state = decoder.call(decoding_input, decoding_hidden, encoding_outputs, decoding_state)\n",
        "        attention_weights = np.reshape(decoding_aw, (-1, 35))\n",
        "        adpre = np.zeros((64,6728))\n",
        "        for index1,sen in enumerate(inp):\n",
        "            for index2, word_index in enumerate(sen):\n",
        "                #int means only integer can be used as indices\n",
        "                adpre[index1][int(word_index)] = attention_weights[index1][index2]\n",
        "            #tf.nn.sigmoid之前shape应该是64,1\n",
        "        prob = tf.nn.sigmoid(W11(context_vector) + W22(decoding_hidden) + W33(decoding_input))\n",
        "        #print(prob.shape)\n",
        "        adpre = tf.convert_to_tensor(adpre,tf.float32)\n",
        "        #prob = tf.conver_to_tensor(prob)\n",
        "        new_prediction = (1-prob) * adpre + prob * predictions\n",
        "        loss += loss_function(targ[:, t+1],new_prediction)\n",
        "            \n",
        "    batch_loss = loss / int(targ.shape[0])\n",
        "    return batch_loss "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35 216\n",
            "(64, 35)\n",
            "(64, 216)\n",
            "tf.Tensor(\n",
            "[[  1 122  12 ...   0   0   0]\n",
            " [  1  75   3 ...   0   0   0]\n",
            " [  1  16 229 ...   0   0   0]\n",
            " ...\n",
            " [  1  18   6 ...   0   0   0]\n",
            " [  1   7  45 ...   0   0   0]\n",
            " [  1  73  41 ...   0   0   0]], shape=(64, 35), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[ 11  42  17 ...   0   0   0]\n",
            " [ 11  84   4 ...   0   0   0]\n",
            " [ 11  28   3 ...   0   0   0]\n",
            " ...\n",
            " [ 11  78  41 ...   0   0   0]\n",
            " [ 11  42  17 ...   0   0   0]\n",
            " [ 11  24 128 ...   0   0   0]], shape=(64, 216), dtype=int32)\n",
            "3492 6728\n",
            "sample_output.shape:  (64, 35, 256)\n",
            "sample_hidden.shape:  (64, 256)\n",
            "sample_memory.shape:  (64, 256)\n",
            "(64, 256)\n",
            "(64, 35, 1)\n",
            "(64, 6728)\n",
            "(64, 256)\n",
            "(64, 35, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YGfFjA-Z0vC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6c9a1944-b5e9-4a83-cf25-e8b063fbca78"
      },
      "source": [
        "#pretraining for 10 epochs\n",
        "adict = {'training_loss':[], 'validation_loss':[]}\n",
        "alist = []\n",
        "import time\n",
        "#epochs = 20\n",
        "epochs = 10\n",
        "# steps_per_epoch = len(input_tensor[192:18973]) // batch_size\n",
        "# steps_per_epoch1 = len(input_tensor[18973:]) // batch_size\n",
        "steps_per_epoch = len(input_train) // batch_size\n",
        "steps_per_epoch1 = len(input_eval) // batch_size\n",
        "for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    \n",
        "    encoding_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "    total_loss1 = 0\n",
        "    for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n",
        "        \n",
        "        batch_loss = train_step(inp, inp, encoding_hidden)\n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:4f}'.format(epoch+1, batch, batch_loss.numpy()))\n",
        "    for (batch1, (inp, targ)) in enumerate(eval_dataset.take(steps_per_epoch1)):\n",
        "        eval_loss = eval_step(inp, inp, encoding_hidden)\n",
        "        total_loss1 += eval_loss\n",
        "               \n",
        "            \n",
        "      \n",
        "    print('Epoch {} Loss {:4f}'.format(epoch+1, total_loss / steps_per_epoch))\n",
        "    print('Epoch {} Eval_Loss {:4f}'.format(epoch+1, total_loss1 / steps_per_epoch1))\n",
        "    print('Time take for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "    adict['training_loss'].append(round(float(total_loss / steps_per_epoch),3))\n",
        "    adict['validation_loss'].append(round(float(total_loss1 / steps_per_epoch1),3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.335792\n",
            "Epoch 1 Batch 100 Loss 1.872304\n",
            "Epoch 1 Batch 200 Loss 1.829018\n",
            "Epoch 1 Loss 1.840016\n",
            "Epoch 1 Eval_Loss 1.844257\n",
            "Time take for 1 epoch 1011.1561205387115 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.684148\n",
            "Epoch 2 Batch 100 Loss 1.209567\n",
            "Epoch 2 Batch 200 Loss 1.200307\n",
            "Epoch 2 Loss 1.413797\n",
            "Epoch 2 Eval_Loss 1.600183\n",
            "Time take for 1 epoch 1006.338672876358 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.370301\n",
            "Epoch 3 Batch 100 Loss 1.350152\n",
            "Epoch 3 Batch 200 Loss 1.057785\n",
            "Epoch 3 Loss 1.180843\n",
            "Epoch 3 Eval_Loss 1.407412\n",
            "Time take for 1 epoch 1001.7600700855255 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.387030\n",
            "Epoch 4 Batch 100 Loss 1.229846\n",
            "Epoch 4 Batch 200 Loss 0.902777\n",
            "Epoch 4 Loss 1.014328\n",
            "Epoch 4 Eval_Loss 1.300056\n",
            "Time take for 1 epoch 1006.7628748416901 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.947921\n",
            "Epoch 5 Batch 100 Loss 0.859225\n",
            "Epoch 5 Batch 200 Loss 0.949001\n",
            "Epoch 5 Loss 0.917270\n",
            "Epoch 5 Eval_Loss 1.214118\n",
            "Time take for 1 epoch 1008.0811765193939 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.894652\n",
            "Epoch 6 Batch 100 Loss 0.946346\n",
            "Epoch 6 Batch 200 Loss 0.826819\n",
            "Epoch 6 Loss 0.878567\n",
            "Epoch 6 Eval_Loss 1.162231\n",
            "Time take for 1 epoch 1005.1480963230133 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.878222\n",
            "Epoch 7 Batch 100 Loss 0.734000\n",
            "Epoch 7 Batch 200 Loss 0.740605\n",
            "Epoch 7 Loss 0.809894\n",
            "Epoch 7 Eval_Loss 1.123462\n",
            "Time take for 1 epoch 1006.7712004184723 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.876968\n",
            "Epoch 8 Batch 100 Loss 0.790984\n",
            "Epoch 8 Batch 200 Loss 0.684334\n",
            "Epoch 8 Loss 0.777345\n",
            "Epoch 8 Eval_Loss 1.086829\n",
            "Time take for 1 epoch 1007.4604732990265 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.721943\n",
            "Epoch 9 Batch 100 Loss 0.641581\n",
            "Epoch 9 Batch 200 Loss 0.620582\n",
            "Epoch 9 Loss 0.743416\n",
            "Epoch 9 Eval_Loss 1.082525\n",
            "Time take for 1 epoch 1006.6522228717804 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.637545\n",
            "Epoch 10 Batch 100 Loss 0.620925\n",
            "Epoch 10 Batch 200 Loss 0.615231\n",
            "Epoch 10 Loss 0.723055\n",
            "Epoch 10 Eval_Loss 1.059837\n",
            "Time take for 1 epoch 1009.7485928535461 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4lUdS9da_RG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "35e849ef-2a1f-4202-f49a-00937580ce61"
      },
      "source": [
        "print(adict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'training_loss': [1.84, 1.414, 1.181, 1.014, 0.917, 0.879, 0.81, 0.777, 0.743, 0.723], 'validation_loss': [1.844, 1.6, 1.407, 1.3, 1.214, 1.162, 1.123, 1.087, 1.083, 1.06]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lHfe6E4Z1cT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "658a007c-2d7e-4c99-d8e9-7a6d3f9f1546"
      },
      "source": [
        "#---------------------------------lstm-----------------------------------------\n",
        "class Decoder(keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_units, decoding_units, batch_size):\n",
        "        super(Decoder, self).__init__()#调用父类（keras.Model）的构造函数\n",
        "        self.batch_size = batch_size\n",
        "        self.decoding_units = decoding_units\n",
        "        self.embedding = keras.layers.Embedding(vocab_size, embedding_units)\n",
        "        self.gru = keras.layers.LSTM(self.decoding_units,\n",
        "                                   return_sequences = True,\n",
        "                                   return_state = True,\n",
        "                                   recurrent_initializer = 'glorot_uniform')\n",
        "        \n",
        "        self.fc = keras.layers.Dense(vocab_size)\n",
        "        self.attention = BahdanauAttention(self.decoding_units)\n",
        "        \n",
        "        #x:当前步输入，hidden:前一步输出\n",
        "    def call(self, x, hidden, encoding_outputs,encoding_state):\n",
        "        #context_vector.shape: (bathc_size, units)\n",
        "        context_vector, attention_weights = self.attention.call(hidden, encoding_outputs)\n",
        "        #befor embedding:x.shape:(batch_size, 1)\n",
        "        #after embedding:x.shape:(batch_size, 1, embedding_units)\n",
        "        \n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        combined_x = tf.concat([tf.expand_dims(context_vector, 1),x], axis = -1)\n",
        "        #output.shape: (batch_size, 1, decoding_units)\n",
        "        #state.shape: (batch_size, decoding_units)\n",
        "        output, state, state_c = self.gru(combined_x, initial_state = [hidden,encoding_state])\n",
        "        #output = keras.layers.Dropout(0.5)(output)\n",
        "        #output.shape: (batch_size, decoding_units)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        \n",
        "        #output.shape: (batch_size, vocab_size)\n",
        "        output = self.fc(output)\n",
        "        \n",
        "        return context_vector, output, state, attention_weights, state_c\n",
        "decoder = Decoder(output_vocab_size, embedding_units, units, batch_size)\n",
        "\n",
        "outputs = decoder.call(tf.random.uniform((batch_size,1)), sample_hidden, sample_output,sample_hidden)\n",
        "\n",
        "context_vector, decoder_output, decoder_hidden, decoder_aw, state_c = outputs\n",
        "\n",
        "print(decoder_output.shape)\n",
        "print(decoder_hidden.shape)\n",
        "print(decoder_aw.shape)\n",
        "\n",
        "optimizer = keras.optimizers.Adam()\n",
        "\n",
        "loss_object = keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = 'none')\n",
        "#from_logits直接经过fc的输出没有经过softmax,如果经过softmax就设成False\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    #输出里的padding不应该计算到损失函数中去\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))#是padding时，mask取0\n",
        "    loss_ = loss_object(real, pred)\n",
        "    mask = tf.cast(mask, dtype = loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    \n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "W11 = keras.layers.Dense(1)\n",
        "W22 = keras.layers.Dense(1)\n",
        "W33 = keras.layers.Dense(1)\n",
        "\n",
        "\n",
        "#lstm-----------------------------------------\n",
        "#@tf.function#加速cell\n",
        "def train_step(inp, targ, encoding_hidden):\n",
        "    loss = 0\n",
        "    with tf.GradientTape() as tape:\n",
        "        encoding_outputs, encoding_hidden, encoding_c = encoder(inp, encoding_hidden)\n",
        "        inp = inp.numpy()\n",
        "        decoding_hidden = encoding_hidden\n",
        "        decoding_state = encoding_c\n",
        "        #eg: <start> I am here <end>\n",
        "        #1. <start> -> I\n",
        "        #2. I -> am\n",
        "        #3. am -> here\n",
        "        #4. here -> <end>\n",
        "        for t in range(0, targ.shape[1]-1):\n",
        "            decoding_input = tf.expand_dims(targ[:, t],1)\n",
        "            context_vector, predictions, decoding_hidden, decoding_aw, decoding_state = decoder.call(decoding_input, decoding_hidden, encoding_outputs,decoding_state)\n",
        "            #由decoding.call返回的三维decoding_aw\n",
        "            attention_weights = np.reshape(decoding_aw, (-1, 35))\n",
        "            adpre = np.zeros((64,6728))\n",
        "            \n",
        "            for index1,sen in enumerate(inp):\n",
        "                for index2, word_index in enumerate(sen):\n",
        "                #int means only integer can be used as indices\n",
        "                    adpre[index1][int(word_index)] = attention_weights[index1][index2]\n",
        "            #tf.nn.sigmoid之前shape应该是64,1\n",
        "            prob = tf.nn.sigmoid(W11(context_vector) + W22(decoding_hidden) + W33(decoding_input))\n",
        "            #print(prob.shape)\n",
        "            adpre = tf.convert_to_tensor(adpre,tf.float32)\n",
        "            #prob = tf.conver_to_tensor(prob)\n",
        "            #print(prob)\n",
        "            #print(adpre)\n",
        "            new_prediction = (1-prob) * adpre + prob * predictions\n",
        "            loss += loss_function(targ[:, t+1],new_prediction)\n",
        "            \n",
        "    batch_loss = loss / int(targ.shape[0])\n",
        "        \n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables + W11.trainable_variables + W22.trainable_variables + W33.trainable_variables\n",
        "        \n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "        \n",
        "    return batch_loss   \n",
        "\n",
        "#-------------------------------------------lstm-------------------------\n",
        "def eval_step(inp, targ, encoding_hidden):\n",
        "    loss = 0\n",
        "    \n",
        "    encoding_outputs, encoding_hidden, encoding_c = encoder(inp, encoding_hidden)\n",
        "    inp = inp.numpy()\n",
        "    decoding_hidden = encoding_hidden\n",
        "    decoding_state = encoding_c\n",
        "        #eg: <start> I am here <end>\n",
        "        #1. <start> -> I\n",
        "        #2. I -> am\n",
        "        #3. am -> here\n",
        "        #4. here -> <end>\n",
        "    for t in range(0, targ.shape[1]-1):\n",
        "        decoding_input = tf.expand_dims(targ[:, t],1)\n",
        "        context_vector, predictions, decoding_hidden, decoding_aw, decoding_state = decoder.call(decoding_input, decoding_hidden, encoding_outputs, decoding_state)\n",
        "        attention_weights = np.reshape(decoding_aw, (-1, 35))\n",
        "        adpre = np.zeros((64,6728))\n",
        "        for index1,sen in enumerate(inp):\n",
        "            for index2, word_index in enumerate(sen):\n",
        "                #int means only integer can be used as indices\n",
        "                adpre[index1][int(word_index)] = attention_weights[index1][index2]\n",
        "            #tf.nn.sigmoid之前shape应该是64,1\n",
        "        prob = tf.nn.sigmoid(W11(context_vector) + W22(decoding_hidden) + W33(decoding_input))\n",
        "        #print(prob.shape)\n",
        "        adpre = tf.convert_to_tensor(adpre,tf.float32)\n",
        "        #prob = tf.conver_to_tensor(prob)\n",
        "        new_prediction = (1-prob) * adpre + prob * predictions\n",
        "        loss += loss_function(targ[:, t+1],new_prediction)\n",
        "            \n",
        "    batch_loss = loss / int(targ.shape[0])\n",
        "    return batch_loss "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 6728)\n",
            "(64, 256)\n",
            "(64, 35, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqRPSKhTaEhs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "outputId": "9e67e660-5d68-4170-f56a-0ae2b6ad3d68"
      },
      "source": [
        "checkpoint_dir = './drive/My Drive/vae_lstm'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)\n",
        "adict = {'training_loss': [], 'validation_loss': []}\n",
        "alist = []\n",
        "import time\n",
        "\n",
        "# epochs = 20\n",
        "epochs = 15\n",
        "# steps_per_epoch = len(input_tensor[192:18973]) // batch_size\n",
        "# steps_per_epoch1 = len(input_tensor[18973:]) // batch_size\n",
        "steps_per_epoch = len(input_train) // batch_size\n",
        "steps_per_epoch1 = len(input_eval) // batch_size\n",
        "for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    encoding_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "    total_loss1 = 0\n",
        "    for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n",
        "        # inp_np = inp.numpy()\n",
        "        # print(type(inp_np))\n",
        "        batch_loss = train_step(inp, targ, encoding_hidden)\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "\n",
        "    for (batch1, (inp, targ)) in enumerate(eval_dataset.take(steps_per_epoch1)):\n",
        "        eval_loss = eval_step(inp, targ, encoding_hidden)\n",
        "        total_loss1 += eval_loss\n",
        "\n",
        "    print('Epoch {} Loss {:4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
        "    print('Epoch {} Eval_Loss {:4f}'.format(epoch + 1, total_loss1 / steps_per_epoch1))\n",
        "    print('Time take for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "    adict['training_loss'].append(round(float(total_loss / steps_per_epoch), 3))\n",
        "    adict['validation_loss'].append(round(float(total_loss1 / steps_per_epoch1), 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 11.287706\n",
            "Epoch 1 Batch 100 Loss 7.182393\n",
            "Epoch 1 Batch 200 Loss 5.538584\n",
            "Epoch 1 Loss 6.957020\n",
            "Epoch 1 Eval_Loss 5.910544\n",
            "Time take for 1 epoch 5891.108117818832 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 5.254960\n",
            "Epoch 2 Batch 100 Loss 4.751407\n",
            "Epoch 2 Batch 200 Loss 4.367440\n",
            "Epoch 2 Loss 4.661715\n",
            "Epoch 2 Eval_Loss 4.647002\n",
            "Time take for 1 epoch 5895.2577431201935 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 4.330440\n",
            "Epoch 3 Batch 100 Loss 3.490721\n",
            "Epoch 3 Batch 200 Loss 3.937353\n",
            "Epoch 3 Loss 3.869163\n",
            "Epoch 3 Eval_Loss 4.167013\n",
            "Time take for 1 epoch 5883.186490535736 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 3.864886\n",
            "Epoch 4 Batch 100 Loss 3.509462\n",
            "Epoch 4 Batch 200 Loss 3.556540\n",
            "Epoch 4 Loss 3.519577\n",
            "Epoch 4 Eval_Loss 3.993120\n",
            "Time take for 1 epoch 5903.610090970993 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 3.435786\n",
            "Epoch 5 Batch 100 Loss 3.498786\n",
            "Epoch 5 Batch 200 Loss 3.870785\n",
            "Epoch 5 Loss 3.317784\n",
            "Epoch 5 Eval_Loss 3.791921\n",
            "Time take for 1 epoch 5924.803283214569 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 2.703157\n",
            "Epoch 6 Batch 100 Loss 3.432184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXjZ1l7Vasfh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(adict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq9bVAYTaK8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import tensorflow as tf\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as  plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "optimizer = keras.optimizers.Adam()\n",
        "checkpoint_dir = './drive/My Drive/vae_lstm'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gFx5RLvaa-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Caution: 在不画图的时候一定要将下面两行代码注释掉\n",
        "import matplotlib.ticker as ticker\n",
        "#-------------------lstm----------------\n",
        "def evaluate(input_sentence):\n",
        "    attention_matrix = np.zeros((max_length_output, max_length_input))\n",
        "    \n",
        "    \n",
        "    inputs = [input_tokenizer.word_index[token] for token in input_sentence.split(' ')]\n",
        "    inputs = keras.preprocessing.sequence.pad_sequences(\n",
        "    [inputs], maxlen=max_length_input, padding='post')\n",
        "    \n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    results = ''\n",
        "    #encoding_hidden = encoder.initialize_hidden_state()\n",
        "    #这里的encoding_hidden在lstm情况下需要改一下维度\n",
        "    encoding_hidden = [tf.zeros((1,units)),tf.zeros((1,units))]\n",
        "    \n",
        "    encoding_outputs, encoding_hidden, encoding_c = encoder(inputs, encoding_hidden)\n",
        "    decoding_hidden = encoding_hidden\n",
        "    decoding_state = encoding_c\n",
        "    #eg: <start> I am here <end>\n",
        "        #1. <start> -> I\n",
        "        #2. I -> am\n",
        "        #3. am -> here\n",
        "        #4. here -> <end>\n",
        "    #decoding_inpu.shape :(1,1)(batch_size, length)\n",
        "    decoding_input = tf.expand_dims([output_tokenizer.word_index['<start>']],0)\n",
        "    for t in range(max_length_output):\n",
        "        #attention_weights.shape: (batch_size, input_length, 1)(1,16,1)\n",
        "        context_vector, predictions, decoding_hidden, decoding_aw, decoding_state = decoder(decoding_input, decoding_hidden, encoding_outputs, decoding_state)\n",
        "        \n",
        "         #-------------------------------------------------------------------------\n",
        "        attention_weights = np.reshape(decoding_aw, (-1, 35))\n",
        "        #经历过上一步后attention_weights.shape = 1,35\n",
        "        adpre = np.zeros((1,6728))\n",
        "        for index1,sen in enumerate(inputs):\n",
        "            for index2, word_index in enumerate(sen):\n",
        "                #int means only integer can be used as indices\n",
        "                adpre[index1][int(word_index)] = attention_weights[index1][index2]\n",
        "            #tf.nn.sigmoid之前shape应该是64,1\n",
        "        prob = tf.nn.sigmoid(W11(context_vector) + W22(decoding_hidden) + W33(decoding_input))\n",
        "        #print(prob.shape)\n",
        "        adpre = tf.convert_to_tensor(adpre,tf.float32)\n",
        "        #prob = tf.conver_to_tensor(prob)\n",
        "        new_prediction = (1-prob) * adpre + prob * predictions\n",
        "        #-------------------------------------------------------------------------------\n",
        "        \n",
        "        attention_weights = tf.reshape(decoding_aw, (-1,))#length=16的向量\n",
        "        attention_matrix[t] = attention_weights.numpy()#attention_weights是一个tensor，用numpy（）取出它的值\n",
        "        #predictions.shape: (batch_size, vocab_size)  (1,4935)\n",
        "        \n",
        "        predicted_id = tf.argmax(new_prediction[0]).numpy()\n",
        "        \n",
        "        results += output_tokenizer.index_word[predicted_id] + ' '\n",
        "        if output_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return results, input_sentence, attention_matrix\n",
        "        \n",
        "        decoding_input = tf.expand_dims([predicted_id],0)\n",
        "    return results, input_sentence, attention_matrix\n",
        "\n",
        "def plot_attention(attention_matrix, input_sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1,1,1)#add a subplot,1,1,1表示子图位置\n",
        "    ax.matshow(attention_matrix, cmap='viridis')#viridis是一种配色方案\n",
        "    \n",
        "    font_dict = {'fontsize': 14}\n",
        "    ax.set_xticklabels([''] + input_sentence, fontdict=font_dict, rotation = 90)#seq2seq里不需要加空格\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=font_dict)\n",
        "    plt.show()\n",
        "\n",
        "def translate(input_sentence):\n",
        "    results, input_sentence, attention_matrix = evaluate(input_sentence)\n",
        "    \n",
        "    #------------------------\n",
        "    \n",
        "    print('Input: %s' % (input_sentence))\n",
        "    print('Predicted translation: %s' % (results))\n",
        "    \n",
        "    #attention_matrix = attention_matrix[:len(results.split(' ')), :len(input_sentence.split(' '))]\n",
        "    \n",
        "    #plot_attention(attention_matrix, input_sentence.split(' '), results.split(' '))\n",
        "    return results\n",
        "\n",
        "\n",
        "#----------------------BLEU and Meteor------------------------------\n",
        "candidates = []\n",
        "candidates_meteor = []\n",
        "for sample1 in clean_summaries[0:192]:\n",
        "    #res = translate(sample1+', ')\n",
        "    res = translate(sample1)\n",
        "    candidates_meteor.append(res)\n",
        "    candidates.append(res.split(' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZlSfaEladUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "score = corpus_bleu(references, candidates,weights=(1,0,0,0))\n",
        "score1 = corpus_bleu(references, candidates,weights=(0.33,0.33,0.33,0))\n",
        "score2 = corpus_bleu(references, candidates,weights=(0.25,0.25,0.25,0.25))\n",
        "print(score,score1,score2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JAborUhafaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_given_item(given_ingredient, generated_recipe):\n",
        "    '''\n",
        "    given_ingredient = ['egg tomatoes','chicken']\n",
        "    splitted_ingredient = [['egg','tomatoes'],['chicken']]\n",
        "    generated_recipe = [['use','egg'],['use','chicken'],...]\n",
        "    '''\n",
        "\n",
        "    total_score = 0\n",
        "    extra_score = 0\n",
        "    splitted_ingredient = []\n",
        "    for bstr in given_ingredient:\n",
        "        splitted_ingredient.append(bstr.split(' '))\n",
        "\n",
        "    for index, each_sample in enumerate(splitted_ingredient):\n",
        "        # count1 covered items\n",
        "        # count2 extra items\n",
        "        count1 = 0\n",
        "        count2 = 0\n",
        "        for each_word in each_sample:\n",
        "            # generated_recipe就是下面的candidates=[['use','egg'],['use','chicken'],...]\n",
        "            if each_word in generated_recipe[index]:\n",
        "                count1 += 1\n",
        "            else:\n",
        "                count2 += 1\n",
        "        extra_score += count2 / len(each_sample)\n",
        "        total_score += count1 / len(each_sample)\n",
        "    # -------------------------------------------------------------------------\n",
        "    for index, each_recipe in enumerate(generated_recipe):\n",
        "        # count1 covered items\n",
        "        # count2 extra items\n",
        "        extra_item = 0\n",
        "        for each_word in each_recipe:\n",
        "            # generated_recipe就是下面的candidates=[['use','egg'],['use','chicken'],...]\n",
        "            if each_word in input_tokenizer.word_index and each_word not in splitted_ingredient[index]:\n",
        "                extra_item += 1\n",
        "\n",
        "    # --------------------------------------------------------------------------\n",
        "\n",
        "    total_score = total_score / len(given_ingredient)\n",
        "\n",
        "    return total_score, extra_item\n",
        "\n",
        "cover_item, extra_item = calculate_given_item(given_ingredient, candidates)\n",
        "print(cover_item,extra_item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGmjCrlsagPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(reference_meteor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebYid8Ypah2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(candidates_meteor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-zeVEP6FaLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}