{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nimport tensorflow as tf\nimport matplotlib as mpl\nimport matplotlib.pyplot as  plt\n#%matplotlib inline jupyternotebook中必须加上这句才能显示图片\nimport numpy as np\nimport pandas as pd\nimport sklearn\nimport os\nimport sys\nimport time\nfrom tensorflow import keras\n#import keras\nprint(tf.__version__)\nprint(sys.version_info)\nfor module in mpl, np, pd, sklearn, tf, keras:\n    print(module.__name__,module.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean = pd.read_csv(\"/kaggle/input/total-data/total_data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#---------------------------------------------------------------------------------------\ngiven_ingredient = list(df_clean.ingredients)[0:192]\n\n\n#-----------------------------创建评估用词表--------------------------------------------\nreference_recipe = list(df_clean.recipes)\nreference_meteor = []\nreferences = []\nreference_list = reference_recipe[0:192]\nfor astr in reference_list:\n    alist = astr.split(' ')[1:-1]\n    reference_meteor.append(' '.join(alist))\n    references.append([alist])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_summaries = list(df_clean.ingredients)\nclean_texts = list(df_clean.recipes)\nprint(clean_summaries[-1])\nprint(clean_texts[-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sp_dataset = tuple(clean_summaries)\nen_dataset = tuple(clean_texts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#将词语式数据转成ID式\ndef tokenizer(lang):\n    lang_tokenizer = keras.preprocessing.text.Tokenizer(\n        num_words=None, filters='', split=' ')\n    lang_tokenizer.fit_on_texts(lang)#统计词频，生成词表\n    tensor = lang_tokenizer.texts_to_sequences(lang)\n    tensor = keras.preprocessing.sequence.pad_sequences(tensor, padding='post')#在句子后面做padding\n    return tensor, lang_tokenizer\n\ninput_tensor, input_tokenizer = tokenizer(sp_dataset)\noutput_tensor, output_tokenizer = tokenizer(en_dataset)\n\ndef max_length(tensor):\n    return max(len(t) for t in tensor)\n\nmax_length_input = max_length(input_tensor)\nmax_length_output = max_length(output_tensor)\nprint(max_length_input, max_length_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(input_tokenizer.word_index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ninput_train, input_eval, output_train, output_eval = train_test_split(input_tensor[192:], output_tensor[192:], test_size=0.01, shuffle=False)\n\nlen(input_train), len(input_eval), len(output_train), len(output_eval)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#验证tokenizer正常工作\ndef convert(example, tokenizer):\n    for t in example:\n        if t != 0:\n            print('%d -- > %s' % (t, tokenizer.index_word[t]))\nconvert(input_train[0], input_tokenizer)\nprint()\nconvert(output_train[0], output_tokenizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#epochs = 20\nbatch_size = 64\nepochs = 20\ndataset = tf.data.Dataset.from_tensor_slices((input_train, output_train))\ntrain_dataset = dataset.repeat(epochs).batch(batch_size, drop_remainder= True)\ntrain_dataset = train_dataset.shuffle(10000)\neval_dataset = tf.data.Dataset.from_tensor_slices((input_eval, output_eval))\neval_dataset = eval_dataset.repeat(epochs).batch(batch_size, drop_remainder= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(eval_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x, y in train_dataset.take(1):\n    print(x.shape)\n    print(y.shape)\n    print(x)\n    print(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#500\nembedding_units = 256\nunits = 256\n#input_tokenizer.word_index是个字典\ninput_vocab_size = len(input_tokenizer.word_index) + 1\noutput_vocab_size = len(output_tokenizer.word_index) + 1\nprint(input_vocab_size,output_vocab_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Encoder(keras.Model):\n    def __init__(self, vocab_size, embedding_units, encoding_units, batch_size):\n        super(Encoder, self).__init__()\n        self.batch_size = batch_size\n        self.encoding_units = encoding_units\n        self.embedding = keras.layers.Embedding(vocab_size, embedding_units)\n        #由于用attention，每步输出需要return_sequences = True\n        self.gru = keras.layers.GRU(self.encoding_units,\n                                   return_sequences = True,\n                                   return_state = True,\n                                   recurrent_initializer = 'glorot_uniform')\n        \n        \n    #hidden是初始化的隐含状态\n    def call(self, x, hidden):\n        x = self.embedding(x)\n        output, state = self.gru(x, initial_state = hidden)\n        return output, state\n    \n    def initialize_hidden_state(self):\n        return tf.zeros((self.batch_size, self.encoding_units))\n    \nencoder = Encoder(input_vocab_size, embedding_units, units, batch_size)\nsample_hidden = encoder.initialize_hidden_state()\nsample_output, sample_hidden = encoder.call(x, sample_hidden)\n\nprint('sample_output.shape: ', sample_output.shape)\nprint('sample_hidden.shape: ', sample_hidden.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#-------------------lstm-----------------------------------\nclass Encoder(keras.Model):\n    def __init__(self, vocab_size, embedding_units, encoding_units, batch_size):\n        super(Encoder, self).__init__()\n        self.batch_size = batch_size\n        self.encoding_units = encoding_units\n        self.embedding = keras.layers.Embedding(vocab_size, embedding_units)\n        #由于用attention，每步输出需要return_sequences = True\n        self.gru = keras.layers.LSTM(self.encoding_units,\n                                   return_sequences = True,\n                                   return_state = True,\n                                   recurrent_initializer = 'glorot_uniform')\n        \n        \n    #hidden是初始化的隐含状态\n    #这里hidden应该变成[hiddenstate,hiddenc]\n    def call(self, x, hidden):\n        x = self.embedding(x)\n        output, state, state_c = self.gru(x, initial_state = hidden)\n        return output, state, state_c\n    \n    def initialize_hidden_state(self):\n        return [tf.zeros((self.batch_size, self.encoding_units)),tf.zeros((self.batch_size, self.encoding_units))]\n    \nencoder = Encoder(input_vocab_size, embedding_units, units, batch_size)\nsample_hidden = encoder.initialize_hidden_state()\nsample_output, sample_hidden, sample_c = encoder.call(x, sample_hidden)\n\nprint('sample_output.shape: ', sample_output.shape)\nprint('sample_hidden.shape: ', sample_hidden.shape)\nprint('sample_memory.shape: ', sample_c.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BahdanauAttention(keras.Model):\n    \n    def __init__(self, units):\n        super(BahdanauAttention, self).__init__()\n        self.W1 = keras.layers.Dense(units)\n        self.W2 = keras.layers.Dense(units)\n        self.V = keras.layers.Dense(1)\n        \n    def call(self, decoder_hidden, encoder_outputs):\n        #decoder_hidden.shape = (batch_size, units)\n        #encoder_outputs.shape = (batch_size, length, units)\n        decoder_hidden_with_time_axis = tf.expand_dims(decoder_hidden, 1)#decoder_hidden.shape = (batch_size, 1, units)\n        #before V:tf.nn.tanh/shape: (batch_size, length, units)\n        #after V:(batch_size, length, 1)\n        score = self.V(\n            tf.nn.tanh(\n                self.W1(encoder_outputs) + self.W2(decoder_hidden_with_time_axis)))\n        \n        #shape: (batch_size, length, 1)\n        attention_weights = tf.nn.softmax(score, axis = 1)\n        #context_vector.shape:(batch_size, length, units)\n        context_vector = attention_weights * encoder_outputs\n        #context_vector.shape:(batch_size, units)\n        context_vector = tf.reduce_sum(context_vector, axis = 1)#在length上求和\n        \n        return context_vector, attention_weights\n\nattention_model = BahdanauAttention(units = 10)#units:经过W1之后的units个数，与batch_size, length, units里units不同\nattention_results, attention_weights = attention_model.call(sample_hidden,sample_output)\n\nprint(attention_results.shape)\nprint(attention_weights.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Decoder(keras.Model):\n    def __init__(self, vocab_size, embedding_units, decoding_units, batch_size):\n        super(Decoder, self).__init__()#调用父类（keras.Model）的构造函数\n        self.batch_size = batch_size\n        self.decoding_units = decoding_units\n        self.embedding = keras.layers.Embedding(vocab_size, embedding_units)\n        self.gru = keras.layers.GRU(self.decoding_units,\n                                   return_sequences = True,\n                                   return_state = True,\n                                   recurrent_initializer = 'glorot_uniform')\n        \n        self.fc = keras.layers.Dense(vocab_size)\n        self.attention = BahdanauAttention(self.decoding_units)\n        \n        #x:当前步输入，hidden:前一步输出\n    def call(self, x, hidden, encoding_outputs):\n        #context_vector.shape: (bathc_size, units)\n        context_vector, attention_weights = self.attention.call(hidden, encoding_outputs)\n        #befor embedding:x.shape:(batch_size, 1)\n        #after embedding:x.shape:(batch_size, 1, embedding_units)\n        \n        x = self.embedding(x)\n        \n        combined_x = tf.concat([tf.expand_dims(context_vector, 1),x], axis = -1)\n        #output.shape: (batch_size, 1, decoding_units)\n        #state.shape: (batch_size, decoding_units)\n        output, state = self.gru(combined_x, initial_state = hidden)\n        \n        #output.shape: (batch_size, decoding_units)\n        output = tf.reshape(output, (-1, output.shape[2]))\n        \n        #output.shape: (batch_size, vocab_size)\n        output = self.fc(output)\n        \n        return output, state, attention_weights\ndecoder = Decoder(output_vocab_size, embedding_units, units, batch_size)\n\noutputs = decoder.call(tf.random.uniform((batch_size,1)), sample_hidden, sample_output)\n\ndecoder_output, decoder_hidden, decoder_aw = outputs\n\nprint(decoder_output.shape)\nprint(decoder_hidden.shape)\nprint(decoder_aw.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#---------------------------------lstm-----------------------------------------\nclass Decoder(keras.Model):\n    def __init__(self, vocab_size, embedding_units, decoding_units, batch_size):\n        super(Decoder, self).__init__()#调用父类（keras.Model）的构造函数\n        self.batch_size = batch_size\n        self.decoding_units = decoding_units\n        self.embedding = keras.layers.Embedding(vocab_size, embedding_units)\n        self.gru = keras.layers.LSTM(self.decoding_units,\n                                   return_sequences = True,\n                                   return_state = True,\n                                   recurrent_initializer = 'glorot_uniform')\n        \n        self.fc = keras.layers.Dense(vocab_size)\n        self.attention = BahdanauAttention(self.decoding_units)\n        \n        #x:当前步输入，hidden:前一步输出\n    def call(self, x, hidden, encoding_outputs):\n        #context_vector.shape: (bathc_size, units)\n        context_vector, attention_weights = self.attention.call(hidden, encoding_outputs)\n        #befor embedding:x.shape:(batch_size, 1)\n        #after embedding:x.shape:(batch_size, 1, embedding_units)\n        \n        x = self.embedding(x)\n        \n        combined_x = tf.concat([tf.expand_dims(context_vector, 1),x], axis = -1)\n        #output.shape: (batch_size, 1, decoding_units)\n        #state.shape: (batch_size, decoding_units)\n        output, state, state_c = self.gru(combined_x)\n        \n        #output.shape: (batch_size, decoding_units)\n        output = tf.reshape(output, (-1, output.shape[2]))\n        \n        #output.shape: (batch_size, vocab_size)\n        output = self.fc(output)\n        \n        return output, state, attention_weights\ndecoder = Decoder(output_vocab_size, embedding_units, units, batch_size)\n\noutputs = decoder.call(tf.random.uniform((batch_size,1)), sample_hidden, sample_output)\n\ndecoder_output, decoder_hidden, decoder_aw = outputs\n\nprint(decoder_output.shape)\nprint(decoder_hidden.shape)\nprint(decoder_aw.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = keras.optimizers.Adam()\n\nloss_object = keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = 'none')\n#from_logits直接经过fc的输出没有经过softmax,如果经过softmax就设成False\n\ndef loss_function(real, pred):\n    #输出里的padding不应该计算到损失函数中去\n    mask = tf.math.logical_not(tf.math.equal(real, 0))#是padding时，mask取0\n    loss_ = loss_object(real, pred)\n    mask = tf.cast(mask, dtype = loss_.dtype)\n    loss_ *= mask\n    \n    return tf.reduce_mean(loss_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@tf.function#加速cell\ndef train_step(inp, targ, encoding_hidden):\n    loss = 0\n    with tf.GradientTape() as tape:\n        encoding_outputs, encoding_hidden = encoder(inp, encoding_hidden)\n        \n        decoding_hidden = encoding_hidden\n        \n        #eg: <start> I am here <end>\n        #1. <start> -> I\n        #2. I -> am\n        #3. am -> here\n        #4. here -> <end>\n        for t in range(0, targ.shape[1]-1):\n            decoding_input = tf.expand_dims(targ[:, t],1)\n            predictions, decoding_hidden, _ = decoder.call(decoding_input, decoding_hidden, encoding_outputs)\n            loss += loss_function(targ[:, t+1],predictions)\n            \n    batch_loss = loss / int(targ.shape[0])\n        \n    variables = encoder.trainable_variables + decoder.trainable_variables\n        \n    gradients = tape.gradient(loss, variables)\n    optimizer.apply_gradients(zip(gradients, variables))\n        \n    return batch_loss            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lstm-----------------------------------------\n@tf.function#加速cell\ndef train_step(inp, targ, encoding_hidden):\n    loss = 0\n    with tf.GradientTape() as tape:\n        encoding_outputs, encoding_hidden, encoding_c = encoder(inp, encoding_hidden)\n        \n        decoding_hidden = encoding_hidden\n        \n        #eg: <start> I am here <end>\n        #1. <start> -> I\n        #2. I -> am\n        #3. am -> here\n        #4. here -> <end>\n        for t in range(0, targ.shape[1]-1):\n            decoding_input = tf.expand_dims(targ[:, t],1)\n            predictions, decoding_hidden, _ = decoder.call(decoding_input, decoding_hidden, encoding_outputs)\n            loss += loss_function(targ[:, t+1],predictions)\n            \n    batch_loss = loss / int(targ.shape[0])\n        \n    variables = encoder.trainable_variables + decoder.trainable_variables\n        \n    gradients = tape.gradient(loss, variables)\n    optimizer.apply_gradients(zip(gradients, variables))\n        \n    return batch_loss    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def eval_step(inp, targ, encoding_hidden):\n    loss = 0\n    \n    encoding_outputs, encoding_hidden = encoder(inp, encoding_hidden)\n        \n    decoding_hidden = encoding_hidden\n        \n        #eg: <start> I am here <end>\n        #1. <start> -> I\n        #2. I -> am\n        #3. am -> here\n        #4. here -> <end>\n    for t in range(0, targ.shape[1]-1):\n        decoding_input = tf.expand_dims(targ[:, t],1)\n        predictions, decoding_hidden, _ = decoder.call(decoding_input, decoding_hidden, encoding_outputs)\n        loss += loss_function(targ[:, t+1],predictions)\n            \n    batch_loss = loss / int(targ.shape[0])\n    return batch_loss ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#-------------------------------------------lstm-------------------------\ndef eval_step(inp, targ, encoding_hidden):\n    loss = 0\n    \n    encoding_outputs, encoding_hidden, encoding_c = encoder(inp, encoding_hidden)\n        \n    decoding_hidden = encoding_hidden\n        \n        #eg: <start> I am here <end>\n        #1. <start> -> I\n        #2. I -> am\n        #3. am -> here\n        #4. here -> <end>\n    for t in range(0, targ.shape[1]-1):\n        decoding_input = tf.expand_dims(targ[:, t],1)\n        predictions, decoding_hidden, _ = decoder.call(decoding_input, decoding_hidden, encoding_outputs)\n        loss += loss_function(targ[:, t+1],predictions)\n            \n    batch_loss = loss / int(targ.shape[0])\n    return batch_loss ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# import time\n# epochs = 10\n# steps_per_epoch = len(input_tensor) // batch_size\n\n# for epoch in range(epochs):\n#     start = time.time()\n    \n#     encoding_hidden = encoder.initialize_hidden_state()\n#     total_loss = 0\n#     total_loss1 = 0\n#     for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n        \n#         batch_loss = train_step(inp, targ, encoding_hidden)\n#         total_loss += batch_loss\n        \n                \n#     print('Epoch {} Loss {:4f}'.format(epoch+1, total_loss / steps_per_epoch))\n#     print('Time take for 1 epoch {} sec\\n'.format(time.time() - start))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adict = {'training_loss':[], 'validation_loss':[]}\nalist = []\nimport time\n#epochs = 20\nepochs = 20\n# steps_per_epoch = len(input_tensor[192:18973]) // batch_size\n# steps_per_epoch1 = len(input_tensor[18973:]) // batch_size\nsteps_per_epoch = len(input_train) // batch_size\nsteps_per_epoch1 = len(input_eval) // batch_size\nfor epoch in range(epochs):\n    start = time.time()\n    \n    encoding_hidden = encoder.initialize_hidden_state()\n    total_loss = 0\n    total_loss1 = 0\n    for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n        \n        batch_loss = train_step(inp, targ, encoding_hidden)\n        total_loss += batch_loss\n        \n        if batch % 100 == 0:\n            print('Epoch {} Batch {} Loss {:4f}'.format(epoch+1, batch, batch_loss.numpy()))\n    for (batch1, (inp, targ)) in enumerate(eval_dataset.take(steps_per_epoch1)):\n        eval_loss = eval_step(inp, targ, encoding_hidden)\n        total_loss1 += eval_loss\n               \n            \n      \n    print('Epoch {} Loss {:4f}'.format(epoch+1, total_loss / steps_per_epoch))\n    print('Epoch {} Eval_Loss {:4f}'.format(epoch+1, total_loss1 / steps_per_epoch1))\n    print('Time take for 1 epoch {} sec\\n'.format(time.time() - start))\n    adict['training_loss'].append(round(float(total_loss / steps_per_epoch),3))\n    adict['validation_loss'].append(round(float(total_loss1 / steps_per_epoch1),3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import time\n# epochs = 10\n# steps_per_epoch = len(input_tensor) // batch_size\n\n# for epoch in range(epochs):\n#     start = time.time()\n    \n#     encoding_hidden = encoder.initialize_hidden_state()\n#     total_loss = 0\n    \n#     for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n        \n#         batch_loss = train_step(inp, targ, encoding_hidden)\n#         total_loss += batch_loss\n        \n#         if batch % 100 == 0:\n#             print('Epoch {} Batch {} Loss {:4f}'.format(epoch+1, batch, batch_loss.numpy()))\n            \n            \n#     print('Epoch {} Loss {:4f}'.format(epoch+1, total_loss / steps_per_epoch))\n#     print('Time take for 1 epoch {} sec\\n'.format(time.time() - start))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(steps_per_epoch)\nprint(adict['validation_loss'])\nprint(adict['training_loss'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as  plt\ndef plot_learning_curves(history, title=None):\n    pd.DataFrame(history).plot(figsize=(8,5))\n    plt.title('Learning curves')\n    plt.xlim(0,20)\n    plt.grid(False)\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.gca().set_ylim(0,7) #设置坐标轴范围, x轴范围是epochs的个数\n    plt.show()\nplot_learning_curves(adict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(adict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(input_sentence):\n    attention_matrix = np.zeros((max_length_output, max_length_input))\n    \n    \n    inputs = [input_tokenizer.word_index[token] for token in input_sentence.split(' ')]\n    inputs = keras.preprocessing.sequence.pad_sequences(\n    [inputs], maxlen=max_length_input, padding='post')\n    \n    inputs = tf.convert_to_tensor(inputs)\n    results = ''\n    #encoding_hidden = encoder.initialize_hidden_state()\n    encoding_hidden = tf.zeros((1,units))\n    \n    encoding_outputs, encoding_hidden = encoder(inputs, encoding_hidden)\n    decoding_hidden = encoding_hidden\n    #eg: <start> I am here <end>\n        #1. <start> -> I\n        #2. I -> am\n        #3. am -> here\n        #4. here -> <end>\n    #decoding_inpu.shape :(1,1)(batch_size, length)\n    decoding_input = tf.expand_dims([output_tokenizer.word_index['<start>']],0)\n    for t in range(max_length_output):\n        #attention_weights.shape: (batch_size, input_length, 1)(1,16,1)\n        predictions, decoding_hidden, attention_weights = decoder(decoding_input, decoding_hidden, encoding_outputs)\n        attention_weights = tf.reshape(attention_weights, (-1,))#length=16的向量\n        attention_matrix[t] = attention_weights.numpy()#attention_weights是一个tensor，用numpy（）取出它的值\n        #predictions.shape: (batch_size, vocab_size)  (1,4935)\n        predicted_id = tf.argmax(predictions[0]).numpy()\n        results += output_tokenizer.index_word[predicted_id] + ' '\n        if output_tokenizer.index_word[predicted_id] == '<end>':\n            return results, input_sentence, attention_matrix\n        \n        decoding_input = tf.expand_dims([predicted_id],0)\n    return results, input_sentence, attention_matrix\n\ndef plot_attention(attention_matrix, input_sentence, predicted_sentence):\n    fig = plt.figure(figsize=(10,10))\n    ax = fig.add_subplot(1,1,1)#add a subplot,1,1,1表示子图位置\n    ax.matshow(attention_matrix, cmap='viridis')#viridis是一种配色方案\n    \n    font_dict = {'fontsize': 14}\n    ax.set_xticklabels([''] + input_sentence, fontdict=font_dict, rotation = 90)#seq2seq里不需要加空格\n    ax.set_yticklabels([''] + predicted_sentence, fontdict=font_dict)\n    plt.show()\n\ndef translate(input_sentence):\n    results, input_sentence, attention_matrix = evaluate(input_sentence)\n    \n    #------------------------\n    \n    print('Input: %s' % (input_sentence))\n    print('Predicted translation: %s' % (results))\n    \n    #attention_matrix = attention_matrix[:len(results.split(' ')), :len(input_sentence.split(' '))]\n    \n    #plot_attention(attention_matrix, input_sentence.split(' '), results.split(' '))\n    return results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#-------------------lstm----------------\ndef evaluate(input_sentence):\n    attention_matrix = np.zeros((max_length_output, max_length_input))\n    \n    \n    inputs = [input_tokenizer.word_index[token] for token in input_sentence.split(' ')]\n    inputs = keras.preprocessing.sequence.pad_sequences(\n    [inputs], maxlen=max_length_input, padding='post')\n    \n    inputs = tf.convert_to_tensor(inputs)\n    results = ''\n    #encoding_hidden = encoder.initialize_hidden_state()\n    #这里的encoding_hidden在lstm情况下需要改一下维度\n    encoding_hidden = [tf.zeros((1,units)),tf.zeros((1,units))]\n    \n    encoding_outputs, encoding_hidden,_ = encoder(inputs, encoding_hidden)\n    decoding_hidden = encoding_hidden\n    #eg: <start> I am here <end>\n        #1. <start> -> I\n        #2. I -> am\n        #3. am -> here\n        #4. here -> <end>\n    #decoding_inpu.shape :(1,1)(batch_size, length)\n    decoding_input = tf.expand_dims([output_tokenizer.word_index['<start>']],0)\n    for t in range(max_length_output):\n        #attention_weights.shape: (batch_size, input_length, 1)(1,16,1)\n        predictions, decoding_hidden, attention_weights = decoder(decoding_input, decoding_hidden, encoding_outputs)\n        attention_weights = tf.reshape(attention_weights, (-1,))#length=16的向量\n        attention_matrix[t] = attention_weights.numpy()#attention_weights是一个tensor，用numpy（）取出它的值\n        #predictions.shape: (batch_size, vocab_size)  (1,4935)\n        predicted_id = tf.argmax(predictions[0]).numpy()\n        results += output_tokenizer.index_word[predicted_id] + ' '\n        if output_tokenizer.index_word[predicted_id] == '<end>':\n            return results, input_sentence, attention_matrix\n        \n        decoding_input = tf.expand_dims([predicted_id],0)\n    return results, input_sentence, attention_matrix\n\ndef plot_attention(attention_matrix, input_sentence, predicted_sentence):\n    fig = plt.figure(figsize=(10,10))\n    ax = fig.add_subplot(1,1,1)#add a subplot,1,1,1表示子图位置\n    ax.matshow(attention_matrix, cmap='viridis')#viridis是一种配色方案\n    \n    font_dict = {'fontsize': 14}\n    ax.set_xticklabels([''] + input_sentence, fontdict=font_dict, rotation = 90)#seq2seq里不需要加空格\n    ax.set_yticklabels([''] + predicted_sentence, fontdict=font_dict)\n    plt.show()\n\ndef translate(input_sentence):\n    results, input_sentence, attention_matrix = evaluate(input_sentence)\n    \n    #------------------------\n    \n    print('Input: %s' % (input_sentence))\n    print('Predicted translation: %s' % (results))\n    \n    #attention_matrix = attention_matrix[:len(results.split(' ')), :len(input_sentence.split(' '))]\n    \n    #plot_attention(attention_matrix, input_sentence.split(' '), results.split(' '))\n    return results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"translate(u'<start> water white salt tomatoes eggs <end>')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"translate(u'skinless boneless chicken breast butter condensed cream chicken soup onion finely diced refrigerated biscuit dough torn pieces, ')\ntranslate(u'condensed cream mushroom soup package dry onion soup mix water pot roast, ')\ntranslate(u'purpose flour baking soda salt butter brown sugar eggs beaten mashed overripe bananas, ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preheat oven to 350 degrees f 175 degrees c . in a medium bowl , mix together the ground beef , and milk . bake in preheated oven for 45 minutes , or until chicken is cooked through .\n# in a medium bowl , mix together the soup , and onion soup mix . cook on low for 8 to 10 minutes .\n# preheat oven to 350 degrees f 175 degrees c . grease and flour a 9x13 inch baking pan . in a large bowl , combine flour , baking powder , and salt . stir in the flour , baking powder , and salt . stir in the flour , baking powder , and salt . stir in the flour , baking powder , and salt . stir in the flour , baking powder , and salt . stir in the flour , baking powder , and salt . stir in the flour , baking powder , and salt . stir in the flour , baking powder , and salt . stir in the flour , baking powder , and salt . stir in the flour , baking powder , and salt . stir in the flour , baking powder , and salt . stir in the flour , baking powder , and salt . stir in the flour , baking powder , and salt . stir in the flour , baking powder , and salt . stir in the flour , baking powder , and salt . stir in the flour , baking powder , and salt . stir in the flour , baking powder , and salt . stir in the flour , baking powder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"translate('<start> tomatoes eggs sugar salt <end>')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(reference_meteor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#----------------------BLEU and Meteor------------------------------\ncandidates = []\ncandidates_meteor = []\nfor sample1 in clean_summaries[0:192]:\n    #res = translate(sample1+', ')\n    res = translate(sample1)\n    candidates_meteor.append(res)\n    candidates.append(res.split(' '))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Input: <start> skinless boneless chicken breast butter condensed cream chicken soup onion finely diced refrigerated biscuit dough torn pieces <end>\nPredicted translation: preheat oven to 350 degrees f 175 degrees c . place chicken in a large bowl . add the butter and cook until the cheese is melted . <end> \nInput: <start> condensed cream mushroom soup package dry onion soup mix water pot roast <end>\nPredicted translation: preheat oven to 350 degrees f 175 degrees c . in a large bowl , mix together the chicken breasts in the heat and refrigerate for at least 1 hour . <end> \nInput: <start> purpose flour baking soda salt butter brown sugar eggs beaten mashed overripe bananas <end>\nPredicted translation: preheat oven to 350 degrees f 175 degrees c . grease a 9x13 inch baking pan . in a large bowl , stir together the flour , baking powder , and salt . stir in the flour , and vanilla . mix in the flour , and vanilla . mix in the flour , and vanilla . mix in the flour , and vanilla . mix in the flour , and vanilla . mix in the flour , and vanilla . mix in the flour , and vanilla . mix in the flour , and vanilla . mix in the flour , and vanilla . mix in the flour , and vanilla . mix in the flour , and vanilla . mix in the flour , and vanilla . mix in the flour , and vanilla . mix in the flour , and vanilla . mix in the flour , and vanilla . mix in the flour , and vanilla . mix in the flour , and vanilla . mix in the flour , and vanilla . mix in the flour , and vanilla . mix in the flour , and vanilla . mix in the flour , and vanilla . mix in the flour , and vanilla . mix in the flour , and vanilla ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# two references for one document\nfrom nltk.translate.bleu_score import corpus_bleu\nscore = corpus_bleu(references, candidates,weights=(1,0,0,0))\nscore1 = corpus_bleu(references, candidates,weights=(0.33,0.33,0.33,0))\nscore2 = corpus_bleu(references, candidates,weights=(0.25,0.25,0.25,0.25))\nprint(score,score1,score2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_given_item(given_ingredient, generated_recipe):\n    '''\n    given_ingredient = ['egg tomatoes','chicken']\n    splitted_ingredient = [['egg','tomatoes'],['chicken']]\n    generated_recipe = [['use','egg'],['use','chicken'],...]\n    '''\n    \n    total_score = 0\n    extra_score = 0\n    splitted_ingredient = []\n    for bstr in given_ingredient: \n        splitted_ingredient.append(bstr.split(' '))\n    \n\n    for index, each_sample in enumerate(splitted_ingredient):\n        #count1 covered items\n        #count2 extra items\n        count1 = 0\n        count2 = 0\n        for each_word in each_sample:\n            #generated_recipe就是下面的candidates=[['use','egg'],['use','chicken'],...]\n            if each_word in generated_recipe[index]:\n                count1 += 1\n            else:\n                count2 += 1\n        extra_score += count2 / len(each_sample)\n        total_score += count1 / len(each_sample)\n#-------------------------------------------------------------------------\n    for index, each_recipe in enumerate(generated_recipe):\n        #count1 covered items\n        #count2 extra items\n        extra_item = 0\n        for each_word in each_recipe:\n            #generated_recipe就是下面的candidates=[['use','egg'],['use','chicken'],...]\n            if each_word in input_tokenizer.word_index and each_word not in splitted_ingredient[index]:\n                extra_item += 1\n                  \n#--------------------------------------------------------------------------      \n    \n    total_score = total_score / len(given_ingredient)\n    \n    return total_score, extra_item\n\n'''\n#testing set\ngiven_ingredient = ['egg tomatoes','chicken banana']\ngenerated_recipe = [['tomatoes','use'],['banana','chicken']]\ncover_item, extra_item = calculate_given_item(given_ingredient, generated_recipe)\nprint(cover_item,extra_item)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cover_item, extra_item = calculate_given_item(given_ingredient, candidates)\nprint(cover_item,extra_item)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(reference_meteor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(candidates_meteor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"translate(u'chicken, water, salt, pepper, ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"translate(u'steak, salt, sugar, eggs, ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"translate(u'butter, pieces, chicken, ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"translate(u'chicken butter onion biscuit dough torn pieces, ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}